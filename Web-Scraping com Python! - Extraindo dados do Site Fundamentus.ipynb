{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas necessárias\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo dados do site **[Fundamentus](https://www.fundamentus.com.br/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos especificar um User Agent para não ser bloqueado por tentar enviar requisições GET pelo Python\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enviando requisição GET para o servidor, solicitando todo documento HTML , passando o parâmetro headers \n",
    "\n",
    "html = requests.get(\"https://www.fundamentus.com.br/detalhes.php?papel=\",headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos utilizar o BeautifulSoup junto com o interpretador HTML para extrair as informações do HTML\n",
    "\n",
    "soup = BeautifulSoup(html.text , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos procurar a tabela principal com todas ações pelo ID \n",
    "\n",
    "tabela = soup.find(id='test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percorrendo todas as colunas da tabela para pegar o nome das colunas.\n",
    "\n",
    "cols = [x.text for x in tabela.findAll('th') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora, percorremos as linhas\n",
    "\n",
    "rows = tabela.findAll('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iremos armazenar todos os dados da tabela em uma lista\n",
    "\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    data_rows = row.findAll('td')\n",
    "    papel = [x.text.strip() for x in data_rows]\n",
    "    data.append([ele for ele in papel])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos remover a primeira linha dessa lista, pois não contém nada.\n",
    "\n",
    "del data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Olha que beleza, lembra do Pandas ? Vamos jogar todo conteúdo da tabela em um dataframe Pandas!\n",
    "\n",
    "acoes_df = pd.DataFrame(data=data , columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acoes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo dados específicos de cada ação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabela específica contendo dados do papel AALR3\n",
    "\n",
    "html = requests.get('https://www.fundamentus.com.br/detalhes.php?papel=AALR3',headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queremos extrair todos os dados dessa página, para isso, precisamos pesquisar as tabelas (Site bem confuso, pois as tabelas distintas possuem mesmo nome)\n",
    "\n",
    "\n",
    "tabela1 = bs.findAll('table', class_='w728')[0]\n",
    "tabela2 = bs.findAll('table', class_='w728')[1]\n",
    "tabela3 = bs.findAll('table', class_='w728')[2]\n",
    "tabela4 = bs.findAll('table', class_='w728')[3]\n",
    "tabela5 = bs.findAll('table', class_='w728')[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> tabela1 - Papel AALR3</center>\n",
    "\n",
    "![](images/fundamentus_aalr3_tabela1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vejamos a tabela1, ela contém algumas informações, tais como: Papel, Tipo, Empresa, Setor , etc ... \n",
    "# Para extrairmos o conteúdo dessa tabela, precisaremos percorrer as colunas , depois as linhas.\n",
    "\n",
    "data= []\n",
    "colunas=[]\n",
    "\n",
    "rows = tabela1.findAll('tr')\n",
    "\n",
    "for row in rows:\n",
    "    data_rows = row.findAll(class_='txt')\n",
    "    data_rows = [ele.text.strip() for ele in data_rows]\n",
    "    data.append([ele for ele in data_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esse site não é tão amigável para se realizar Web Scraping\n",
    "#não é tão simples separar os nomes das colunas com os dados contidos nas colunas..\n",
    "\n",
    "\n",
    "colunas = []\n",
    "valores = []\n",
    "\n",
    "for i in range(0,len(data)-1):\n",
    "    for j in range(0,len(data[0])):\n",
    "        if i%2 == 0:\n",
    "            colunas.append(data[j][i])\n",
    "        else:\n",
    "            valores.append(data[j][i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conseguimos! Vamos para a tabela2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> tabela2 - Papel AALR3</center>\n",
    "\n",
    "![](images/fundamentus_aalr3_tabela2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= []\n",
    "\n",
    "\n",
    "rows = tabela2.findAll('tr')\n",
    "\n",
    "for row in rows:\n",
    "    data_rows = row.findAll(class_='txt')\n",
    "    data_rows = [ele.text.strip() for ele in data_rows]\n",
    "    data2.append([ele for ele in data_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos armazenar o conteúdo da tabela2 na mesma lista que já criamos para a tabela1\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    for j in range(0,len(data2[0])):\n",
    "        if j%2 == 0:\n",
    "            colunas.append(data2[i][j])\n",
    "        else:\n",
    "            valores.append(data2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora, tabela3 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> tabela3 - Papel AALR3</center>\n",
    "\n",
    "![](images/fundamentus_aalr3_tabela3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = []\n",
    "\n",
    "rows = tabela3.findAll('tr')\n",
    "\n",
    "for row in rows:\n",
    "    data_r = row.find_all(class_=['txt','oscil'])\n",
    "    data_r = [ele.text.strip() for ele in data_r]\n",
    "    data3.append([ele for ele in data_r ]) \n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nossa, que mistura doida ! Bem vindos ao Web Scraping raiz ! \n",
    "#Vamos pensar em algum padrão para que possamos armazenar esses dados\n",
    "\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos percorrer as linhas e as colunas dessa lista, de modo que consigamos separar as linhas das colunas , e adicionar um \n",
    "#prefixo para as colunas que são relacionadas a 'Oscilações'\n",
    "\n",
    "for i in range(1,len(data3)):\n",
    "    for j in range(0,2):\n",
    "        if j%2 == 0:\n",
    "            colunas.append('oscilacoes_'+data3[i][j])\n",
    "        else:    \n",
    "            valores.append(data3[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faremos o mesmo para as que tem relação com 'Indicadores fundamentalistas'\n",
    "\n",
    "\n",
    "for i in range(1,len(data3)):\n",
    "    for j in range(2,6):\n",
    "        if j%2 == 0:\n",
    "            colunas.append('ind_fund_'+data3[i][j])\n",
    "        else:    \n",
    "            valores.append(data3[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não acaba nunca ? Vamos para a tabela4!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> tabela4 - Papel AALR3</center>\n",
    "\n",
    "![](images/fundamentus_aalr3_tabela4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = []\n",
    "\n",
    "rows = tabela4.findAll('tr')\n",
    "\n",
    "for row in rows:\n",
    "    data_r = row.find_all(class_=['txt','oscil'])\n",
    "    data_r = [ele.text.strip() for ele in data_r]\n",
    "    data4.append([ele for ele in data_r ]) \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(data4)):\n",
    "    for j in range(0,4):\n",
    "        if j%2 == 0:\n",
    "            colunas.append('dados_b_patr_'+data4[i][j])\n",
    "        else:    \n",
    "            valores.append(data4[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The last one ! Tabela5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> tabela5 - Papel AALR3</center>\n",
    "\n",
    "![](images/fundamentus_aalr3_tabela5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = []\n",
    "\n",
    "rows = tabela5.findAll('tr')\n",
    "\n",
    "for row in rows:\n",
    "    data_r = row.find_all(class_=['txt','oscil'])\n",
    "    data_r = [ele.text.strip() for ele in data_r]\n",
    "    data5.append([ele for ele in data_r ]) \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_ = []\n",
    "valores_ = []\n",
    "for i in range(2,len(data5)):\n",
    "    for j in range(0,2):\n",
    "        if j%2 == 0:\n",
    "            colunas.append('ult_12_m_'+data5[i][j])\n",
    "        else:    \n",
    "            valores.append(data5[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(2,len(data5)):\n",
    "    for j in range(2,4):\n",
    "        if j%2 == 0:\n",
    "            colunas.append('ult_3_m_'+data5[i][j])\n",
    "        else:    \n",
    "            valores.append(data5[i][j])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente, vamos ver o resultado em um dataframe ?\n",
    "\n",
    "pd.DataFrame(data=[valores] , columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora queremos pegar as informações de TODOS papeis disponíveis no site! Agora a coisa ficou séria !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos separar o nome de todas as ações disponíveis no site, em seguida explicarei o porque disso.\n",
    "\n",
    "papeis= list(acoes_df['Papel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O Site fundamentus possui um padrão nos links, isso vai nos facilitar bastante,podemos percorrer cada link e extrair o conteúdo de cada ação!\n",
    "\n",
    "for link in soup.findAll('a'):\n",
    "    print(link.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos percorrer cada ação, conforme abaixo:\n",
    "\n",
    "\n",
    "#listas contendo as ações que falharem e as que conseguimos extrair, para controle.\n",
    "error_list = []\n",
    "success_list = []\n",
    "\n",
    "\n",
    "for papel in papeis:\n",
    "\n",
    "    html = requests.get('https://www.fundamentus.com.br/detalhes.php?papel={}'.format(papel),headers=header)\n",
    "\n",
    "\n",
    "\n",
    "    bs = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "    #Bloco try para tratamento de erros durante a extração, os sites possuem diferenças nas telas, \n",
    "    #isso dificulta a extração, e vários outros problemas também podem ocorrer, devemos tratar cada um deles.\n",
    "    try:\n",
    "        tabela1 = bs.findAll('table', class_='w728')[0]\n",
    "        tabela2 = bs.findAll('table', class_='w728')[1]\n",
    "        tabela3 = bs.findAll('table', class_='w728')[2]\n",
    "        #tabela4 = bs.findAll('table', class_='w728')[3]\n",
    "        tabela5 = bs.findAll('table', class_='w728')[4]\n",
    "\n",
    "\n",
    "\n",
    "        data= []\n",
    "        colunas=[]\n",
    "\n",
    "        rows = tabela1.findAll('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            data_rows = row.findAll(class_='txt')\n",
    "            data_rows = [ele.text.strip() for ele in data_rows]\n",
    "            data.append([ele for ele in data_rows])\n",
    "\n",
    "\n",
    "\n",
    "        colunas = []\n",
    "        valores = []\n",
    "\n",
    "        for i in range(0,len(data)-1):\n",
    "            for j in range(0,len(data[0])):\n",
    "                if i%2 == 0:\n",
    "                    colunas.append(data[j][i])\n",
    "                else:\n",
    "                    valores.append(data[j][i])\n",
    "                \n",
    "\n",
    "        data2= []\n",
    "\n",
    "\n",
    "        rows = tabela2.findAll('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            data_rows = row.findAll(class_='txt')\n",
    "            data_rows = [ele.text.strip() for ele in data_rows]\n",
    "            data2.append([ele for ele in data_rows])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(0,len(data2)):\n",
    "            for j in range(0,len(data2[0])):\n",
    "                if j%2 == 0:\n",
    "                    colunas.append(data2[i][j])\n",
    "                else:\n",
    "                    valores.append(data2[i][j])\n",
    "\n",
    "\n",
    "\n",
    "        data3 = []\n",
    "\n",
    "        rows = tabela3.findAll('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            data_r = row.find_all(class_=['txt','oscil'])\n",
    "            data_r = [ele.text.strip() for ele in data_r]\n",
    "            data3.append([ele for ele in data_r ]) \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(1,len(data3)):\n",
    "            for j in range(0,2):\n",
    "                if j%2 == 0:\n",
    "                    colunas.append('oscilacoes_'+data3[i][j])\n",
    "                else:    \n",
    "                    valores.append(data3[i][j])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(1,len(data3)):\n",
    "            for j in range(2,6):\n",
    "                if j%2 == 0:\n",
    "                    colunas.append('ind_fund_'+data3[i][j])\n",
    "                else:    \n",
    "                    valores.append(data3[i][j])\n",
    "                \n",
    "\n",
    "        #Não iremos extrair a tabela4 das ações, uma vez que existem particularidades, as colunas mudam dependendo da ação.\n",
    "        \n",
    "        #data4 = []\n",
    "\n",
    "        #rows = tabela4.findAll('tr')\n",
    "\n",
    "        #for row in rows:\n",
    "            #data_r = row.find_all(class_=['txt','oscil'])\n",
    "            #data_r = [ele.text.strip() for ele in data_r]\n",
    "            #data4.append([ele for ele in data_r ]) \n",
    "          \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "        #for i in range(1,len(data4)):\n",
    "            #for j in range(0,4):\n",
    "                #if j%2 == 0:\n",
    "                    #colunas.append('dados_b_patr_'+data4[i][j])\n",
    "                #else:    \n",
    "                    #valores.append(data4[i][j])\n",
    "                \n",
    "\n",
    "\n",
    "        data5 = []\n",
    "\n",
    "        rows = tabela5.findAll('tr')\n",
    "\n",
    "        for row in rows:\n",
    "            data_r = row.find_all(class_=['txt','oscil'])\n",
    "            data_r = [ele.text.strip() for ele in data_r]\n",
    "            data5.append([ele for ele in data_r ]) \n",
    "          \n",
    "            \n",
    "\n",
    "        colunas_ = []\n",
    "        valores_ = []\n",
    "        for i in range(2,len(data5)):\n",
    "            for j in range(0,2):\n",
    "                if j%2 == 0:\n",
    "                    colunas.append('ult_12_m_'+data5[i][j])\n",
    "                else:    \n",
    "                    valores.append(data5[i][j])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        for i in range(2,len(data5)):\n",
    "            for j in range(2,4):\n",
    "                if j%2 == 0:\n",
    "                    colunas.append('ult_3_m_'+data5[i][j])\n",
    "                else:    \n",
    "                    valores.append(data5[i][j])\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        tabela_ok = pd.DataFrame(data=[valores] , columns=colunas)\n",
    "\n",
    "\n",
    "        from time import gmtime, strftime\n",
    "        actual_date= strftime(\"%Y%m%d\", gmtime())\n",
    "\n",
    "        \n",
    "        #criando variável sistêmica para controle.\n",
    "        tabela_ok['data_processamento'] = actual_date\n",
    "        \n",
    "        filename = 'C:/Users/Felipe/Desktop/acoes_teste.csv'\n",
    "        \n",
    "        #Salvando o resultado de cada ação em um CSV, iremos desprezar o header do CSV a partir da segunda execução.\n",
    "        tabela_ok.to_csv(filename,sep=';',mode='a',index=False,encoding='latin1',header=(not os.path.exists(filename)))\n",
    "\n",
    "        print('Papel extraído com sucesso  > ',papel)\n",
    "        success_list.append(papel)\n",
    "    except IndexError:\n",
    "        print(\"Erro ao extrair >\" ,papel)\n",
    "        error_list.append(papel)\n",
    "    except Exception as e:\n",
    "        print(\"Erro no Servidor :\",e)\n",
    "        \n",
    "        #Aguardando um tempo, para não derrubar o servidor! (não façam isso em casa) rs\n",
    "        time.sleep(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
